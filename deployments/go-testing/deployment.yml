---
### TEMPLATE FOR A SERVICE AND DEPLOYMENT ON KUBERNETES just substitute the next keywords with your own values
### go-cloud-k8s-user-group     : the name of your application or container image
### v0.3.2  : the version of the app image to deploy
### ghcr.io/lao-tseu-is-alive  : the prefix to your images in your container registry
apiVersion: v1
kind: Namespace
metadata:
  name: go-testing
  labels:
    env: test
    app: goeland
    # https://kubernetes.io/docs/concepts/security/pod-security-admission/
    # The per-mode level label indicates which policy level to apply for the mode.
    # MODE must be one of `enforce`, `audit`, or `warn`.
    # LEVEL must be one of `privileged`, `baseline`, or `restricted`.
    # pod-security.kubernetes.io/<MODE>: <LEVEL>
    pod-security.kubernetes.io/enforce: restricted
    pod-security.kubernetes.io/enforce-version: latest
    pod-security.kubernetes.io/warn: restricted
    pod-security.kubernetes.io/warn-version: latest
---
apiVersion: v1
kind: ResourceQuota
metadata:
  name: compute-resources
  namespace: go-testing
  labels:
    app: go-cloud-k8s-user-group
spec:
### ADAPT the values above to your need remember that you m
  hard:
    requests.cpu: "8"
    requests.memory: 8Gi
    limits.cpu: "16"
    limits.memory: 16Gi
---
## https://kubernetes.io/docs/tasks/administer-cluster/manage-resources/memory-default-namespace/
apiVersion: v1
kind: LimitRange
metadata:
  name: mem-limit-range
spec:
  limits:
    - default:
        memory: 512Mi
      defaultRequest:
        memory: 256Mi
      type: Container
---
## https://kubernetes.io/docs/tasks/administer-cluster/manage-resources/cpu-default-namespace/
apiVersion: v1
kind: LimitRange
metadata:
  name: cpu-limit-range
spec:
  limits:
    - default:
        cpu: "1"
      defaultRequest:
        cpu: "0.5"
      type: Container
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  namespace: go-testing
  name: pod-reader-role
  labels:
    app: go-cloud-k8s-user-group
rules:
  - apiGroups: [""]  # "" indicates the core API group
    resources: ["pods", "namespaces"]
    verbs: ["get", "watch", "list"]
# to allow reading pods logs with : kubectl logs -l app=go-cloud-k8s-shell --all-containers=true -n test-go-cloud-k8s-shell
  - apiGroups: [""]
    resources: ["pods/log"]
    verbs: ["get"]
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: pod-reader-role-binding
  labels:
    app: go-cloud-k8s-user-group
subjects:
  - kind: Group
    name: system:serviceaccounts
    apiGroup: rbac.authorization.k8s.io
roleRef:
  kind: ClusterRole
  name: pod-reader-role
  apiGroup: rbac.authorization.k8s.io
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: service-reader-role
  labels:
    app: go-cloud-k8s-user-group
rules:
  - apiGroups: [""]
    resources: ["services"]
    verbs: ["get", "watch", "list"]
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: service-reader-role-binding
  labels:
    app: go-cloud-k8s-user-group
subjects:
  - kind: Group
    name: system:serviceaccounts
    apiGroup: rbac.authorization.k8s.io
roleRef:
  kind: ClusterRole
  name: service-reader-role
  apiGroup: rbac.authorization.k8s.io
---
apiVersion: v1
kind: Service                    # Type of kubernetes resource
metadata:
  name: go-cloud-k8s-user-group-service   # Name of the resource
  namespace: go-testing
  labels:     # The labels that will be applied
    app: go-cloud-k8s-user-group
  annotations:
    externalTrafficPolicy: "local"
spec:
  #type: NodePort                 # A port is opened on each node in your cluster via Kube proxy.
  # https://kubernetes.io/docs/concepts/services-networking/service/#loadbalancer
  type: LoadBalancer             # Adds a load balancer (from the cloud provider)
  # k3s will deploy a daemonset listening on the given port on the host node
  # By default k3s have a builtin load balancer called "klipper" https://github.com/k3s-io/klipper-lb ok for one dev node.
  # It is possible to run multiple Services on the same node, as long as they use different ports.
  # in case you are using a 'real' k3s cluster with multiple nodes consider using metalLB instead
  externalTrafficPolicy: Local
  loadBalancerSourceRanges:
    - 192.168.0.0/16
  ports:                         # Take incoming HTTP requests on this port (exposed) and forward them to the targetPort of container
    - name: http
      port: 8000
      targetPort: my-http-port            # Should match the PORT env variable in deployment and containerPort that the Go application listens on
  selector:
    app: go-cloud-k8s-user-group         # Map any pod with this label `app=go-cloud-k8s-user-group` to this service
---
apiVersion: apps/v1
kind: Deployment                 # Type of Kubernetes resource
metadata:
  name: go-cloud-k8s-user-group           # Name of the Kubernetes resource
  namespace: go-testing
  labels:
    app: go-cloud-k8s-user-group
spec:
  replicas: 2                    # Number of pods to run at any given time
  revisionHistoryLimit: 5        # The number of old ReplicaSets to retain to allow rollback
  minReadySeconds: 5             # Minimum number of seconds for which a newly created pod should be ready without any of its container crashing, for it to be considered available. Defaults to 0 (pod will be considered available as soon as it is ready)
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxUnavailable: 1
      maxSurge: 1               # maximum number of pods that can be scheduled above the desired number of pods.
  selector:
    matchLabels:
      app: go-cloud-k8s-user-group              # This deployment applies to any Pods matching the specified label
  template:                      # This deployment will create a set of pods using the configurations in this template
    metadata:
      labels:                    # The labels that will be applied to all the pods in this deployment
        app: go-cloud-k8s-user-group
    spec:                        # Spec for the Pod base config, securityContext can be overridden in container
      # kubectl label nodes gok8sw01.lausanne.ch kubernetes.io/role=worker
      # comment the two next lines if you do not have worker nodes (rancher-desktop)
      #nodeSelector:
      #  node-type: worker
      securityContext:           # https://kubernetes.io/docs/tasks/configure-pod-container/security-context/
        seccompProfile:
          type: RuntimeDefault   # https://kubernetes.io/docs/tutorials/security/seccomp/
        runAsUser: 12121           # using a non privileged user
        runAsGroup: 12121          # using the group 'gouser' created in Dockerfile
        fsGroup: 100             # by adding fsGroup field, all processes of the container are also part
                                 # of the supplementary group ID 100 (users).
        supplementalGroups:
          - 100
      automountServiceAccountToken: false
      containers:
      - name: go-cloud-k8s-user-group
        image: ghcr.io/lao-tseu-is-alive/go-cloud-k8s-user-group:v0.3.3
        imagePullPolicy: Always
        securityContext:
          seccompProfile:
            type: RuntimeDefault
          allowPrivilegeEscalation: false
          runAsNonRoot: true
          runAsUser: 12121           # using the user 'gouser' created in Dockerfile
          runAsGroup: 12121          # using the group 'gouser' created in Dockerfile
          capabilities:
            drop:
              - 'ALL'
          readOnlyRootFilesystem: true
        ports:
          - containerPort: 8888   # The port that the Go application listens on
            name: my-http-port
        resources:
          limits:            # resource limit imposed to the pod, the container cannot utilize more res than specified
            cpu: 1000m       # 1000 millicpu or millicores 1 or 100% of a CPU core of a running node
            memory: 128Mi
            ephemeral-storage: "2Gi"
          requests:          # explicit request of the minimum amount of resources the pod need
            cpu: 100m        # 100 millicpu or millicores 0.1 or 10% of a CPU core of a running node
            memory: 32Mi
            ephemeral-storage: "1Gi"
        livenessProbe:           # To check the health of the Pod
          httpGet:
            path: /health
            port: my-http-port
            scheme: HTTP
          initialDelaySeconds: 5
          periodSeconds: 15
          timeoutSeconds: 2
        readinessProbe:          # To check if the Pod is ready to serve traffic or not
          httpGet:
            path: /readiness
            port: my-http-port
            scheme: HTTP
          initialDelaySeconds: 5
          timeoutSeconds: 2
        env:
          - name: PORT
            valueFrom:
                configMapKeyRef:
                    key: PORT
                    name: app-config-go-cloud-k8s-user-group
          - name: DB_DRIVER
            valueFrom:
              configMapKeyRef:
                key: DB_DRIVER
                name: app-config-go-cloud-k8s-user-group
          - name: DB_HOST
            valueFrom:
              configMapKeyRef:
                key: DB_HOST
                name: app-config-go-cloud-k8s-user-group
          - name: DB_PORT
            valueFrom:
              configMapKeyRef:
                key: DB_PORT
                name: app-config-go-cloud-k8s-user-group
          - name: DB_NAME
            valueFrom:
              configMapKeyRef:
                key: DB_NAME
                name: app-config-go-cloud-k8s-user-group
          - name: DB_USER
            valueFrom:
              configMapKeyRef:
                key: DB_USER
                name: app-config-go-cloud-k8s-user-group
          - name: DB_PASSWORD
            valueFrom:
              configMapKeyRef:
                key: DB_PASSWORD
                name: app-config-go-cloud-k8s-user-group
          - name: DB_SSL_MODE
            valueFrom:
              configMapKeyRef:
                key: DB_SSL_MODE
                name: app-config-go-cloud-k8s-user-group
          - name: JWT_SECRET
            valueFrom:
              configMapKeyRef:
                key: JWT_SECRET
                name: app-config-go-cloud-k8s-user-group
          - name: JWT_ISSUER_ID
            valueFrom:
              configMapKeyRef:
                key: JWT_ISSUER_ID
                name: app-config-go-cloud-k8s-user-group
          - name: JWT_CONTEXT_KEY
            valueFrom:
              configMapKeyRef:
                key: JWT_CONTEXT_KEY
                name: app-config-go-cloud-k8s-user-group
          - name: JWT_DURATION_MINUTES
            valueFrom:
              configMapKeyRef:
                key: JWT_DURATION_MINUTES
                name: app-config-go-cloud-k8s-user-group
          - name: ADMIN_USER
            valueFrom:
              configMapKeyRef:
                key: ADMIN_USER
                name: app-config-go-cloud-k8s-user-group
          - name: ADMIN_EMAIL
            valueFrom:
              configMapKeyRef:
                key: ADMIN_EMAIL
                name: app-config-go-cloud-k8s-user-group
          - name: ADMIN_ID
            valueFrom:
              configMapKeyRef:
                key: ADMIN_ID
                name: app-config-go-cloud-k8s-user-group
          - name: ADMIN_EXTERNAL_ID
            valueFrom:
              configMapKeyRef:
                key: ADMIN_EXTERNAL_ID
                name: app-config-go-cloud-k8s-user-group
          - name: ADMIN_PASSWORD
            valueFrom:
              configMapKeyRef:
                key: ADMIN_PASSWORD
                name: app-config-go-cloud-k8s-user-group
          - name: MY_NODE_NAME
            valueFrom:
              fieldRef:
                fieldPath: spec.nodeName
          - name: MY_POD_NAME
            valueFrom:
              fieldRef:
                fieldPath: metadata.name
          - name: MY_POD_NAMESPACE
            valueFrom:
              fieldRef:
                fieldPath: metadata.namespace
          - name: MY_POD_IP
            valueFrom:
              fieldRef:
                fieldPath: status.podIP
          - name: MY_POD_SERVICE_ACCOUNT
            valueFrom:
              fieldRef:
                fieldPath: spec.serviceAccountName
